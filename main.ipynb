{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ee79c1-bee6-4f73-9e5a-61d84b28fd8d",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da357a-2bae-439b-85f3-d9297387dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41c01f-95f1-42a1-bd2a-2d7e698b7561",
   "metadata": {},
   "source": [
    "## Formal Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbf87e-0f57-40d8-a733-2d3cf8861acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5107d-eb79-42e3-93d8-47a8854950f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392f706-bf7f-4e48-8d9e-78c7da77456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afe306-3c1d-45dd-a9b0-ee24e298a1ab",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9bcda9-6876-411c-bbd0-7a6abd5a9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size,nb_classes):\n",
    "  inputs = Input(input_size)\n",
    "\n",
    "  conv1 = Conv2D(8, 3, input_shape=input_size, activation='relu', padding='same',\n",
    "                         kernel_initializer='he_normal')(inputs)\n",
    "  conv2 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "  merge1 = concatenate([conv1, conv2], axis=3)\n",
    "\n",
    "  mp1 = MaxPooling2D((2,2))(merge1)\n",
    "  drop1 = Dropout(0.2)(mp1)\n",
    "\n",
    "  conv3 = Conv2D(8, 3, activation='relu', padding='same',\n",
    "                        kernel_initializer='he_normal')(drop1)\n",
    "  conv4 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "  merge2 = concatenate([conv3, conv4], axis=3)\n",
    "\n",
    "  mp2 = MaxPooling2D((2, 2))(merge2)\n",
    "  drop2 = Dropout(0.35)(mp2)\n",
    "  conv5 = Conv2D(16, 3, activation='relu', padding='same',\n",
    "                        kernel_initializer='he_normal')(drop2)\n",
    "  conv6 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "  merge3 = concatenate([conv5, conv6], axis=3)\n",
    "\n",
    "  mp3 = MaxPooling2D((2, 2))(merge3)\n",
    "\n",
    "  conv7 = Conv2D(16, 3, activation='relu', padding='same',\n",
    "                        kernel_initializer='he_normal')(mp3)\n",
    "  conv8 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "  merge3 = concatenate([conv7, conv8], axis=3)\n",
    "\n",
    "  conv9 = Conv2D(32, 3, activation='relu', padding='same',\n",
    "                  kernel_initializer='he_normal')(merge3)\n",
    "  conv10 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "  merge4 = concatenate([conv9, conv10], axis=3)\n",
    "\n",
    "  mp4 = MaxPooling2D((2, 2))(merge4)\n",
    "\n",
    "  conv11 = Conv2D(32, 3, activation='relu', padding='same',\n",
    "                  kernel_initializer='he_normal')(mp4)\n",
    "  conv12 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv11)\n",
    "  merge5 = concatenate([conv11, conv12], axis=3)\n",
    "\n",
    "  conv13 = Conv2D(64, 3, activation='relu', padding='same',\n",
    "                  kernel_initializer='he_normal')(merge5)\n",
    "  conv14 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv13)\n",
    "  merge6 = concatenate([conv13, conv14], axis=3)\n",
    "\n",
    "  conv15 = Conv2D(64, 3, activation='relu', padding='same',\n",
    "                  kernel_initializer='he_normal')(merge6)\n",
    "  conv16 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv15)\n",
    "  merge7 = concatenate([conv15, conv16], axis=3)\n",
    "\n",
    "  mp5 = MaxPooling2D((2, 2))(merge7)\n",
    "\n",
    "  drop4 = Dropout(0.35)(mp5)\n",
    "  flat = Flatten()(drop4)\n",
    "\n",
    "  dense1 = Dense(nb_classes, activation='softmax')(flat)\n",
    "\n",
    "  return Model(inputs, dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083a15b-0c53-4f2b-b66d-fd5f5c7ee4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model((img_width, img_height , 3) , num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9fc61-8b1d-4de2-bebd-cc9baf0ca235",
   "metadata": {},
   "source": [
    "## Model Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecdd56-386a-4c94-945a-327bae2b6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CategoricalCrossentropy()\n",
    "metrics = [CategoricalAccuracy()]\n",
    "optimizer = Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01236652-cd88-492c-bda2-c97872d2c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d1d12-e70b-4757-ae4a-36e1b03ab707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6e62f-d6f2-4a25-a57d-b2993c99e362",
   "metadata": {},
   "source": [
    "## Fitting The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488776e-fe85-4d21-a68f-d6ca63b7e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    ")\n",
    "stopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6c75a-ae34-4065-b5cf-47a77b45870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint , stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf18a24-c734-487a-ba2d-b72987fc4a41",
   "metadata": {},
   "source": [
    "## Saving Settings and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586b111-0b4e-4bed-b4a4-8b16abd049ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba1cee-9870-430c-a45b-e4ae8d506012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "with open('classes.h5' , 'wb') as f:\n",
    "    dump(train_generator.class_indices , f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
